# Training configuration for STK continuous actions with SB3 PPO

# Env
env_id: "supertuxkart/flattened_continuous_actions-v0"
track: "hacienda"
n_envs: 4
seed: 123

# Paths
tb_log_dir: "tensorboard/ppo_stk_continuous"
run_name: "ppo_stk_continuous_1"
out_dir: "q-supertuxkart/continuous"
checkpoints_dir: "q-supertuxkart/continuous/checkpoints"

# VecNormalize
norm_obs_keys: ["continuous"]
clip_obs: 10.0
clip_reward: 10.0
gamma: 0.99

# PPO hyperparams
learning_rate: 1.0e-4
n_steps: 2048
batch_size: 64
n_epochs: 10
gae_lambda: 0.95
clip_range: 0.2
ent_coef: 0.01
vf_coef: 0.5
max_grad_norm: 0.5
clip_range_vf: 1.0
target_kl: 0.02
use_sde: true
sde_sample_freq: 64
total_timesteps: 2000000

# Callbacks
eval_freq: 10000
n_eval_episodes: 5
checkpoint_freq: 0

# Reward shaping
enable_reward_shaping: true

# Reward shaping normalization clips (to prevent reward explosions)
# fwd_clip: approximate max forward speed used for normalization
# lat_clip: approximate max lateral speed used for normalization
fwd_clip: 30.0
lat_clip: 10.0

# Center-line keeping (penalize absolute center_path_distance)
# Increase `w_center` to force the kart to stay closer to the middle of the lane.
# `center_clip` is the absolute distance (in track units) where the penalty saturates.
w_center: 0.2
center_clip: 5.0

# Optional: map indices in obs["continuous"] to semantic signals for shaping (adjust if known)
# obs_index_map:
#   forward_speed: 20
#   lateral_speed: 23
#   off_track: 91
#   center_path_distance: 15
